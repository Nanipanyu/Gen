"""
CNN-LSTM Network for Peak Ground Acceleration (PGA) Prediction

This module implements a CNN-LSTM architecture to predict the PGA of broadband 
earthquake signals generated by the diffusion transformer.

Author: Adapted for earthquake signal analysis
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

class CNNBlock(nn.Module):
    """CNN block for extracting temporal features from seismic signals"""
    def __init__(self, input_channels=2, filter_depths=[32, 64, 128, 256], kernel_size=3):
        super().__init__()
        
        self.conv_layers = nn.ModuleList()
        self.batch_norms = nn.ModuleList()
        
        in_channels = input_channels
        for depth in filter_depths:
            # Convolutional layer
            conv = nn.Conv1d(in_channels, depth, kernel_size=kernel_size, 
                           padding=kernel_size//2, bias=False)
            self.conv_layers.append(conv)
            
            # Batch normalization
            bn = nn.BatchNorm1d(depth)
            self.batch_norms.append(bn)
            
            in_channels = depth
        
        self.activation = nn.ReLU()
        self.dropout = nn.Dropout(0.1)
        
    def forward(self, x):
        # x shape: (batch, channels, seq_len)
        for conv, bn in zip(self.conv_layers, self.batch_norms):
            x = conv(x)
            x = bn(x)
            x = self.activation(x)
            x = self.dropout(x)
        
        return x

class LSTMBlock(nn.Module):
    """Bidirectional LSTM block for capturing temporal dependencies"""
    def __init__(self, input_size, hidden_sizes=[512, 256], dropout=0.1):
        super().__init__()
        
        self.lstm_layers = nn.ModuleList()
        
        in_size = input_size
        for hidden_size in hidden_sizes:
            lstm = nn.LSTM(in_size, hidden_size, batch_first=True, 
                          bidirectional=True, dropout=dropout if len(hidden_sizes) > 1 else 0)
            self.lstm_layers.append(lstm)
            in_size = hidden_size * 2  # Bidirectional doubles the output size
        
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x):
        # x shape: (batch, seq_len, features)
        for lstm in self.lstm_layers:
            x, _ = lstm(x)
            x = self.dropout(x)
        
        return x

class PGAPredictor(nn.Module):
    """
    CNN-LSTM network for predicting PGA from combined low-frequency and broadband signals
    
    Args:
        seq_len: Length of input time series
        cnn_filters: List of CNN filter depths [32, 64, 128, 256]
        lstm_hidden: List of LSTM hidden sizes [512, 256]
        kernel_size: CNN kernel size
        dropout: Dropout rate
    """
    def __init__(self, seq_len=4096, cnn_filters=[32, 64, 128, 256], 
                 lstm_hidden=[512, 256], kernel_size=3, dropout=0.1):
        super().__init__()
        
        self.seq_len = seq_len
        
        # CNN block for feature extraction
        # Input has 2 channels: [low_freq_signal, broadband_signal]
        self.cnn_block = CNNBlock(
            input_channels=2, 
            filter_depths=cnn_filters, 
            kernel_size=kernel_size
        )
        
        # Calculate the feature size after CNN
        cnn_output_channels = cnn_filters[-1]
        
        # LSTM block for temporal modeling
        self.lstm_block = LSTMBlock(
            input_size=cnn_output_channels,
            hidden_sizes=lstm_hidden,
            dropout=dropout
        )
        
        # Final output layers
        lstm_output_size = lstm_hidden[-1] * 2  # Bidirectional LSTM
        self.output_layers = nn.Sequential(
            nn.Linear(lstm_output_size, 128),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(64, 1)  # Single PGA value
        )
        
        # Initialize weights
        self.apply(self._init_weights)
    
    def _init_weights(self, module):
        if isinstance(module, nn.Linear):
            nn.init.normal_(module.weight, std=0.02)
            if module.bias is not None:
                nn.init.zeros_(module.bias)
        elif isinstance(module, nn.Conv1d):
            nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')
    
    def forward(self, x_low, x_broad):
        """
        Args:
            x_low: Low-frequency signal (batch, seq_len) - unnormalized
            x_broad: Broadband signal (batch, seq_len) - normalized
        
        Returns:
            pga_pred: Predicted PGA values (batch, 1)
        """
        batch_size = x_low.shape[0]
        
        # Combine signals as 2-channel input
        x_combined = torch.stack([x_low, x_broad], dim=1)  # (batch, 2, seq_len)
        
        # Extract features with CNN
        cnn_features = self.cnn_block(x_combined)  # (batch, filters[-1], seq_len)
        
        # Transpose for LSTM: (batch, seq_len, features)
        cnn_features = cnn_features.transpose(1, 2)
        
        # Process with LSTM
        lstm_features = self.lstm_block(cnn_features)  # (batch, seq_len, lstm_hidden[-1]*2)
        
        # Global max pooling over time dimension to get fixed-size representation
        pooled_features, _ = torch.max(lstm_features, dim=1)  # (batch, lstm_hidden[-1]*2)
        
        # Predict PGA
        pga_pred = self.output_layers(pooled_features)  # (batch, 1)
        
        return pga_pred

class EarthquakeDataProcessor:
    """Utility class for processing earthquake data for PGA prediction"""
    
    @staticmethod
    def normalize_by_pga(signal):
        """Normalize signal by its PGA"""
        pga = torch.max(torch.abs(signal), dim=-1, keepdim=True)[0]
        # Avoid division by zero
        pga = torch.clamp(pga, min=1e-8)
        return signal / pga, pga
    
    @staticmethod
    def compute_pga(signal):
        """Compute Peak Ground Acceleration"""
        return torch.max(torch.abs(signal), dim=-1)[0]
    
    @staticmethod
    def prepare_training_data(x_low_unnorm, y_broad_unnorm):
        """
        Prepare training data for PGA prediction
        
        Args:
            x_low_unnorm: Unnormalized low-frequency signals (batch, seq_len)
            y_broad_unnorm: Unnormalized broadband signals (batch, seq_len)
        
        Returns:
            x_low: Unnormalized low-frequency signals
            y_broad_norm: Normalized broadband signals
            pga_true: True PGA values
        """
        # Normalize broadband signals by their PGA
        y_broad_norm, pga_true = EarthquakeDataProcessor.normalize_by_pga(y_broad_unnorm)
        
        return x_low_unnorm, y_broad_norm, pga_true.squeeze(-1)

# Loss function for PGA prediction
class PGALoss(nn.Module):
    """Custom loss function for PGA prediction with multiple metrics"""
    def __init__(self, alpha=0.7):
        super().__init__()
        self.alpha = alpha
        self.mse = nn.MSELoss()
        self.l1 = nn.L1Loss()
    
    def forward(self, pred, target):
        # Combine MSE and L1 loss
        mse_loss = self.mse(pred.squeeze(), target)
        l1_loss = self.l1(pred.squeeze(), target)
        
        total_loss = self.alpha * mse_loss + (1 - self.alpha) * l1_loss
        
        return total_loss, mse_loss, l1_loss

# Test the model
if __name__ == "__main__":
    # Test with sample data
    batch_size = 8
    seq_len = 4096
    
    # Create sample signals
    x_low = torch.randn(batch_size, seq_len) * 0.1  # Low-frequency (smaller amplitude)
    x_broad = torch.randn(batch_size, seq_len) * 0.5  # Broadband (normalized)
    
    # Initialize model
    model = PGAPredictor(seq_len=seq_len)
    
    # Forward pass
    with torch.no_grad():
        pga_pred = model(x_low, x_broad)
        print(f"Low-freq input shape: {x_low.shape}")
        print(f"Broadband input shape: {x_broad.shape}")
        print(f"PGA prediction shape: {pga_pred.shape}")
        print(f"Sample PGA predictions: {pga_pred.squeeze()}")
    
    # Test data processor
    processor = EarthquakeDataProcessor()
    x_low_test = torch.randn(4, 1000) * 0.2
    y_broad_test = torch.randn(4, 1000) * 0.8
    
    x_low_proc, y_broad_norm, pga_true = processor.prepare_training_data(x_low_test, y_broad_test)
    print(f"Processed data shapes: {x_low_proc.shape}, {y_broad_norm.shape}, {pga_true.shape}")
    print(f"True PGA values: {pga_true}")
    
    # Test loss function
    loss_fn = PGALoss()
    pga_pred_test = torch.randn(4, 1) * 0.5
    total_loss, mse_loss, l1_loss = loss_fn(pga_pred_test, pga_true)
    print(f"Total loss: {total_loss:.4f}, MSE: {mse_loss:.4f}, L1: {l1_loss:.4f}")
    
    print("PGA Predictor test successful!")
